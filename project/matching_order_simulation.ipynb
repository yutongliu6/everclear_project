{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>currency_symbol</th>\n",
       "      <th>source_chain_name</th>\n",
       "      <th>destination_chain_name</th>\n",
       "      <th>amount</th>\n",
       "      <th>entity_identifier</th>\n",
       "      <th>bridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-05 07:30:59+00:00</td>\n",
       "      <td>BNB</td>\n",
       "      <td>Linea</td>\n",
       "      <td>Base</td>\n",
       "      <td>61.737951</td>\n",
       "      <td>0x328d8c40d596220446eae5b5bec134a1ff247c53ea45...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-05 07:40:38+00:00</td>\n",
       "      <td>BNB</td>\n",
       "      <td>Solana</td>\n",
       "      <td>Arbitrum</td>\n",
       "      <td>43.339604</td>\n",
       "      <td>0x94ecbf840c2a053e2c3fdca3796a757e48e852f2a258...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-05 07:41:41+00:00</td>\n",
       "      <td>BNB</td>\n",
       "      <td>Linea</td>\n",
       "      <td>BNB Chain</td>\n",
       "      <td>309.415405</td>\n",
       "      <td>0x0fa2eabf7160e81d09cba6943429d7b0a765bc74e526...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-05 07:43:17+00:00</td>\n",
       "      <td>BNB</td>\n",
       "      <td>Solana</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>43.284276</td>\n",
       "      <td>0x91b62472ebc5a36ce1081fae3ea7f96467d38730b00a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-05 07:43:35+00:00</td>\n",
       "      <td>BNB</td>\n",
       "      <td>Optimism</td>\n",
       "      <td>Arbitrum</td>\n",
       "      <td>247.734805</td>\n",
       "      <td>0xc23ab0e81427f1eab2be95f90debb904c63fd45f266f...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time currency_symbol source_chain_name  \\\n",
       "0  2024-07-05 07:30:59+00:00             BNB             Linea   \n",
       "1  2024-07-05 07:40:38+00:00             BNB            Solana   \n",
       "2  2024-07-05 07:41:41+00:00             BNB             Linea   \n",
       "3  2024-07-05 07:43:17+00:00             BNB            Solana   \n",
       "4  2024-07-05 07:43:35+00:00             BNB          Optimism   \n",
       "\n",
       "  destination_chain_name      amount  \\\n",
       "0                   Base   61.737951   \n",
       "1               Arbitrum   43.339604   \n",
       "2              BNB Chain  309.415405   \n",
       "3               Optimism   43.284276   \n",
       "4               Arbitrum  247.734805   \n",
       "\n",
       "                                   entity_identifier bridge  \n",
       "0  0x328d8c40d596220446eae5b5bec134a1ff247c53ea45...    NaN  \n",
       "1  0x94ecbf840c2a053e2c3fdca3796a757e48e852f2a258...    NaN  \n",
       "2  0x0fa2eabf7160e81d09cba6943429d7b0a765bc74e526...    NaN  \n",
       "3  0x91b62472ebc5a36ce1081fae3ea7f96467d38730b00a...    NaN  \n",
       "4  0xc23ab0e81427f1eab2be95f90debb904c63fd45f266f...    NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "data = pd.read_csv(r\"bridge-transactions.csv\")\n",
    "MAIN = [\"Ethereum\", \"BNB Chain\", \"Solana\", \"Optimism\", \"Arbitrum\", \"Avalanche\"]\n",
    "LONG_TAIL = [\"Base\", \"Polygon\", \"Linea\"]\n",
    "ALL_CHAINS = MAIN + LONG_TAIL\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Linea', 'Solana', 'Optimism', 'Arbitrum', 'Base', 'Ethereum',\n",
       "       'Polygon', 'BNB Chain', 'Avalanche'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source_chain_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Base', 'Arbitrum', 'BNB Chain', 'Optimism', 'Polygon', 'Solana',\n",
       "       'Ethereum', 'Linea'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['destination_chain_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.date(2024, 7, 5), datetime.date(2024, 8, 2))\n"
     ]
    }
   ],
   "source": [
    "data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "date = data['date_time'].apply(lambda x: x.date)\n",
    "print((date.min(), date.max()))\n",
    "data['date'] = date\n",
    "data = data.sort_values('date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2a2ebab434b5>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_subset['bin'] = pd.cut(data_subset['date_time'], date_cut)\n"
     ]
    }
   ],
   "source": [
    "data_subset = data[data['date'] == pd.to_datetime('20240708')]\n",
    "date_cut = list(data_subset.set_index('date_time').groupby(pd.Grouper(freq='30min'))['currency_symbol'].count().index)\n",
    "date_cut.append(date_cut[-1] + dt.timedelta(minutes=30))\n",
    "data_subset['bin'] = pd.cut(data_subset['date_time'], date_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "main_discount = 0.8e-4\n",
    "long_tail_discount = 2e-4\n",
    "slippage = {\"Ethereum\": 5e-6, \"BNB Chain\": 7.5e-6, \"Solana\": 1e-5, \"Optimism\": 1e-5, \"Arbitrum\": 2e-5,\n",
    "            \"Base\": 5e-5, \"Polygon\": 5e-5, \"Linea\": 7.5e-5, \"Avalanche\": 1e-5,\n",
    "           }\n",
    "\n",
    "def sim_one_day(df, main_discount, long_tail_discount, slippage):\n",
    "    accounting = defaultdict(float)\n",
    "    trace = defaultdict(list)\n",
    "\n",
    "    for currency_symbol in df['currency_symbol'].unique():\n",
    "        prev_grouped = None\n",
    "        cur = df[df['currency_symbol']==currency_symbol]\n",
    "        trace = []\n",
    "        iteration = 0\n",
    "        for b in cur['bin'].unique().sort_values():\n",
    "            epoch = cur[cur['bin']==b].set_index(['currency_symbol', 'source_chain_name', 'destination_chain_name'])\n",
    "            grouped = epoch.groupby(level=[0,1,2]).sum().xs(currency_symbol)\n",
    "            accounting[f\"{currency_symbol}_protocol_fee\"] += grouped.sum().iloc[0] * 1e-4\n",
    "\n",
    "            # keep trace of all order\n",
    "            curr_trace = grouped.copy(deep=True)\n",
    "            curr_trace[\"epoch\"] = iteration\n",
    "            trace.append(curr_trace)\n",
    "\n",
    "            # add orders from previous epoch\n",
    "            if prev_grouped is not None:\n",
    "                grouped = grouped.append(prev_grouped)\n",
    "                grouped = grouped.groupby(level=[0,1]).sum()\n",
    "\n",
    "            # detect matches\n",
    "            while True:\n",
    "                G=nx.DiGraph()\n",
    "                G.add_nodes_from(list(grouped.index.get_level_values(0)) + list(grouped.index.get_level_values(1)))\n",
    "                G.add_edges_from(list(grouped.index), weight=grouped)\n",
    "                cycles = list(nx.simple_cycles(G))\n",
    "                if not len(cycles) > 0:\n",
    "                    break\n",
    "                weighted_cycles = []\n",
    "                for cycle in cycles:\n",
    "                    min_weight = float(\"inf\")\n",
    "                    for i in range(len(cycle)-1):\n",
    "                        weight = grouped.loc[pd.IndexSlice[cycle[i], cycle[i+1]]].values\n",
    "                        min_weight = min(weight, min_weight)\n",
    "                    weighted_cycles.append([min_weight * len(cycle)] + cycle)\n",
    "                weighted_cycles = sorted(weighted_cycles, key=lambda x: -x[0])\n",
    "                greedy = weighted_cycles[0]\n",
    "                for i in range(1, len(greedy)-1):\n",
    "                    grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]] -= greedy[0] / (len(greedy)-1)\n",
    "                    accounting[f\"{currency_symbol}_matched\"] += greedy[0][0]\n",
    "                    if grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]].values < 0 - 1e-4:\n",
    "                        raise ValueError(\"Cannot have negative orders!\")\n",
    "                    elif grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]].values < 0 + 1e-4:\n",
    "                        grouped.drop([pd.IndexSlice[greedy[i], greedy[i+1]]], inplace=True)\n",
    "\n",
    "            # accounting\n",
    "            trace_sum = pd.concat(trace).drop(\"epoch\", axis=1).groupby(level=[0,1]).sum()\n",
    "            diff = trace_sum - grouped.reindex(trace_sum.index).fillna(0)\n",
    "            diff = diff[diff>0].dropna()\n",
    "            for idx, row in diff.iterrows():\n",
    "                amount = row.iloc[0]\n",
    "                while True:\n",
    "                    try:\n",
    "                        for i in range(len(trace)):\n",
    "                            if idx in trace[i].index:\n",
    "                                delta = min(trace[i].loc[idx, \"amount\"], amount) \n",
    "                                trace[i].loc[idx, \"amount\"] -= delta\n",
    "                                amount -= delta\n",
    "                                if trace[i].loc[idx, \"amount\"] < 0 + 1e-4:\n",
    "                                    trace[i].drop(idx, inplace=True)\n",
    "                                # trick to break the while loop\n",
    "                                if amount < 0 + 1e-4:\n",
    "                                    raise Exception\n",
    "                    except:\n",
    "                        break\n",
    "            trace_sum = pd.concat(trace).drop(\"epoch\", axis=1).groupby(level=[0,1]).sum()\n",
    "            diff = trace_sum - grouped.reindex(trace_sum.index).fillna(0)\n",
    "            if diff.sum().iloc[0] > 1e-4:\n",
    "                raise ValueError(\"Wrong accounting\")\n",
    "            trace = [t for t in trace if len(t) > 0]\n",
    "\n",
    "            # discount this epoch\n",
    "            undiscounted = grouped.copy(deep=True)\n",
    "            discounted = grouped.copy(deep=True)        \n",
    "            discounted.loc[pd.IndexSlice[:, MAIN], :] *= (1-main_discount)\n",
    "            discounted.loc[pd.IndexSlice[:, LONG_TAIL], :] *= (1-long_tail_discount)\n",
    "            discount_loss = undiscounted - discounted\n",
    "            accounting[f\"{currency_symbol}_discount_loss\"] += discount_loss.sum().iloc[0]\n",
    "\n",
    "\n",
    "            # clear orders filled by discounts\n",
    "            for i in range(len(trace)):\n",
    "                curr = trace[i]\n",
    "                if len(curr) > 0:\n",
    "                    for idx, row in curr.iterrows():\n",
    "                        if row.iloc[0] > 1e-4:\n",
    "                            fee = slippage[idx[0]] + slippage[idx[1]]\n",
    "                            if idx[1] in MAIN:\n",
    "                                discount = main_discount * (iteration - trace[i][\"epoch\"].iloc[0])\n",
    "                            if idx[1] in LONG_TAIL:\n",
    "                                discount = long_tail_discount * (iteration - trace[i][\"epoch\"].iloc[0])\n",
    "                            \n",
    "                            grouped.loc[idx] -= min(grouped.loc[idx].iloc[0], discount / fee) \n",
    "\n",
    "            # drop cleared orders\n",
    "            grouped = grouped[grouped > 0+1e-4].dropna()\n",
    "            prev_grouped = grouped\n",
    "            iteration += 1\n",
    "        accounting[f\"{currency_symbol}_eod_remain\"] = grouped.sum().iloc[0]\n",
    "    return accounting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {'BNB_protocol_fee': 0.3286162282536421,\n",
       "             'BNB_discount_loss': 0.762453483209498,\n",
       "             'BNB_eod_remain': 143.9011226843943,\n",
       "             'WETH_protocol_fee': 1.2194748334315078,\n",
       "             'WETH_discount_loss': 2.079309638713685,\n",
       "             'WETH_eod_remain': 6471.966857625832})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_one_day(data_subset,main_discount,long_tail_discount,slippage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# consolidated_results = {}\n",
    "# for date in data.date.unique():\n",
    "#     print(date)\n",
    "#     data_subset = data[data['date'] == date]\n",
    "#     date_cut = list(data_subset.set_index('date_time').groupby(pd.Grouper(freq='30min'))['currency_symbol'].count().index)\n",
    "#     date_cut.append(date_cut[-1] + dt.timedelta(minutes=30))\n",
    "#     data_subset['bin'] = pd.cut(data_subset['date_time'], date_cut)\n",
    "#     accounting = sim_one_day(data_subset,main_discount,long_tail_discount,slippage)\n",
    "#     consolidated_results[date] = accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(consolidated_results).T.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-c996059e5e95>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_subset['bin'] = pd.cut(data_subset['date_time'], date_cut)\n"
     ]
    }
   ],
   "source": [
    "# continuous sim\n",
    "data_with_bin = []\n",
    "for date in data.date.unique():\n",
    "#     print(date)\n",
    "    data_subset = data[data['date'] == date]\n",
    "    date_cut = list(data_subset.set_index('date_time').groupby(pd.Grouper(freq='30min'))['currency_symbol'].count().index)\n",
    "    date_cut.append(date_cut[-1] + dt.timedelta(minutes=30))\n",
    "    data_subset['bin'] = pd.cut(data_subset['date_time'], date_cut)\n",
    "    data_with_bin.append(data_subset)\n",
    "\n",
    "data_with_bin = pd.concat(data_with_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Interval('2024-07-05 07:30:00', '2024-07-05 08:00:00', closed='right'),\n",
       "       Interval('2024-07-05 08:00:00', '2024-07-05 08:30:00', closed='right'),\n",
       "       Interval('2024-07-05 08:30:00', '2024-07-05 09:00:00', closed='right'),\n",
       "       ...,\n",
       "       Interval('2024-08-02 01:00:00', '2024-08-02 01:30:00', closed='right'),\n",
       "       Interval('2024-08-02 01:30:00', '2024-08-02 02:00:00', closed='right'),\n",
       "       Interval('2024-08-02 02:00:00', '2024-08-02 02:30:00', closed='right')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_bin['bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_bin.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continous_sim(df, main_discount, long_tail_discount, slippage):\n",
    "    accounting = defaultdict(lambda: defaultdict(float))\n",
    "    trace = defaultdict(list)\n",
    "\n",
    "    for currency_symbol in df['currency_symbol'].unique():\n",
    "        prev_grouped = None\n",
    "        cur = df[df['currency_symbol']==currency_symbol]\n",
    "        trace = []\n",
    "        iteration = 0\n",
    "        for i, b in enumerate(sorted(cur['bin'].unique())):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{i} iterations passed\")\n",
    "            epoch = cur[cur['bin']==b].set_index(['currency_symbol', 'source_chain_name', 'destination_chain_name'])\n",
    "            date = epoch[\"date\"].unique()[0]\n",
    "\n",
    "            grouped = epoch.groupby(level=[0,1,2]).sum().xs(currency_symbol)\n",
    "            accounting[date][f\"{currency_symbol}_protocol_fee\"] += grouped.sum().iloc[0] * 1e-4\n",
    "\n",
    "            # keep trace of all order\n",
    "            curr_trace = grouped.copy(deep=True)\n",
    "            curr_trace[\"epoch\"] = iteration\n",
    "            trace.append(curr_trace)\n",
    "\n",
    "            # add orders from previous epoch\n",
    "            if prev_grouped is not None:\n",
    "                grouped = grouped.append(prev_grouped)\n",
    "                grouped = grouped.groupby(level=[0,1]).sum()\n",
    "\n",
    "            # detect matches\n",
    "            while True:\n",
    "                G=nx.DiGraph()\n",
    "                G.add_nodes_from(list(grouped.index.get_level_values(0)) + list(grouped.index.get_level_values(1)))\n",
    "                G.add_edges_from(list(grouped.index), weight=grouped)\n",
    "                cycles = list(nx.simple_cycles(G))\n",
    "                if not len(cycles) > 0:\n",
    "                    break\n",
    "                weighted_cycles = []\n",
    "                for cycle in cycles:\n",
    "                    min_weight = float(\"inf\")\n",
    "                    for i in range(len(cycle)-1):\n",
    "                        weight = grouped.loc[pd.IndexSlice[cycle[i], cycle[i+1]]].values\n",
    "                        min_weight = min(weight, min_weight)\n",
    "                    weighted_cycles.append([min_weight * len(cycle)] + cycle)\n",
    "                weighted_cycles = sorted(weighted_cycles, key=lambda x: -x[0])\n",
    "                greedy = weighted_cycles[0]\n",
    "                for i in range(1, len(greedy)-1):\n",
    "                    grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]] -= greedy[0] / (len(greedy)-1)\n",
    "                    accounting[date][f\"{currency_symbol}_matched\"] += greedy[0][0]\n",
    "                    if grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]].values < 0 - 1e-4:\n",
    "                        raise ValueError(\"Cannot have negative orders!\")\n",
    "                    elif grouped.loc[pd.IndexSlice[greedy[i], greedy[i+1]]].values < 0 + 1e-4:\n",
    "                        grouped.drop([pd.IndexSlice[greedy[i], greedy[i+1]]], inplace=True)\n",
    "\n",
    "            # accounting\n",
    "            trace_sum = pd.concat(trace).drop(\"epoch\", axis=1).groupby(level=[0,1]).sum()\n",
    "            diff = trace_sum - grouped.reindex(trace_sum.index).fillna(0)\n",
    "            diff = diff[diff>0].dropna()\n",
    "            for idx, row in diff.iterrows():\n",
    "                amount = row.iloc[0]\n",
    "                while True:\n",
    "                    try:\n",
    "                        for i in range(len(trace)):\n",
    "                            if idx in trace[i].index:\n",
    "                                delta = min(trace[i].loc[idx, \"amount\"], amount) \n",
    "                                trace[i].loc[idx, \"amount\"] -= delta\n",
    "                                amount -= delta\n",
    "                                if trace[i].loc[idx, \"amount\"] < 0 + 1e-4:\n",
    "                                    trace[i].drop(idx, inplace=True)\n",
    "                                # trick to break the while loop\n",
    "                                if amount < 0 + 1e-4:\n",
    "                                    raise Exception\n",
    "                    except:\n",
    "                        break\n",
    "            trace_sum = pd.concat(trace).drop(\"epoch\", axis=1).groupby(level=[0,1]).sum()\n",
    "            diff = trace_sum - grouped.reindex(trace_sum.index).fillna(0)\n",
    "            if diff.sum().iloc[0] > 1e-4:\n",
    "                raise ValueError(\"Wrong accounting\")\n",
    "            trace = [t for t in trace if len(t) > 0]\n",
    "            # discount this epoch\n",
    "            undiscounted = grouped.copy(deep=True)\n",
    "            discounted = grouped.copy(deep=True)        \n",
    "            discounted.loc[pd.IndexSlice[:, MAIN], :] *= (1-main_discount)\n",
    "            discounted.loc[pd.IndexSlice[:, LONG_TAIL], :] *= (1-long_tail_discount)\n",
    "            discount_loss = undiscounted - discounted\n",
    "            accounting[date][f\"{currency_symbol}_discount_loss\"] += discount_loss.sum().iloc[0]\n",
    "\n",
    "\n",
    "            # clear orders filled by discounts\n",
    "            for i in range(len(trace)):\n",
    "                curr = trace[i]\n",
    "                if len(curr) > 0:\n",
    "                    for idx, row in curr.iterrows():\n",
    "                        if row.iloc[0] > 1e-4:\n",
    "                            fee = slippage[idx[0]] + slippage[idx[1]]\n",
    "                            if idx[1] in MAIN:\n",
    "                                discount = main_discount * (iteration - trace[i][\"epoch\"].iloc[0])\n",
    "                            if idx[1] in LONG_TAIL:\n",
    "                                discount = long_tail_discount * (iteration - trace[i][\"epoch\"].iloc[0])\n",
    "                          \n",
    "                            grouped.loc[idx] -= min(grouped.loc[idx].iloc[0], discount / fee)        \n",
    "\n",
    "            # drop cleared orders\n",
    "            grouped = grouped[grouped > 0+1e-4].dropna()\n",
    "            prev_grouped = grouped\n",
    "            iteration += 1\n",
    "        accounting[date][f\"{currency_symbol}_eod_remain\"] = grouped.sum().iloc[0]\n",
    "    return accounting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n"
     ]
    }
   ],
   "source": [
    "consolidated_results = continous_sim(data_with_bin, main_discount, long_tail_discount, slippage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(consolidated_results).T.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "600 iterations passed\n",
      "700 iterations passed\n",
      "800 iterations passed\n",
      "900 iterations passed\n",
      "0 iterations passed\n",
      "100 iterations passed\n",
      "200 iterations passed\n",
      "300 iterations passed\n",
      "400 iterations passed\n",
      "500 iterations passed\n",
      "0 iterations passed\n"
     ]
    }
   ],
   "source": [
    "main_discount_params = [1e-4, 2.5e-4, 5e-4]\n",
    "long_tail_discount_params = [5e-4, 10e-4]\n",
    "all_res = defaultdict(lambda: defaultdict())\n",
    "for md in main_discount_params:\n",
    "    for ld in long_tail_discount_params:\n",
    "        accounting = continous_sim(data_with_bin, md, ld, slippage)\n",
    "        all_res[md][ld] = accounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_m_five_l = pd.DataFrame(all_res[1e-4][5e-4]).T\n",
    "one_m_ten_l = pd.DataFrame(all_res[1e-4][10e-4]).T\n",
    "twopfive_m_five_l = pd.DataFrame(all_res[2.5e-4][5e-4]).T\n",
    "twopfive_m_ten_l = pd.DataFrame(all_res[2.5e-4][10e-4]).T\n",
    "five_m_five_l = pd.DataFrame(all_res[5e-4][5e-4]).T\n",
    "five_m_ten_l = pd.DataFrame(all_res[5e-4][10e-4]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = one_m_five_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "loss2 = one_m_ten_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "loss3 = twopfive_m_five_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "loss4 = twopfive_m_ten_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "loss5 = five_m_five_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "loss6 = five_m_ten_l[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n",
    "\n",
    "loss0 = pd.DataFrame(consolidated_results).T[['BNB_discount_loss', 'WETH_discount_loss', 'WBTC_discount_loss']].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([loss0, loss1, loss2, loss3, loss4, loss5, loss6],axis=1).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = one_m_five_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "loss2 = one_m_ten_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "loss3 = twopfive_m_five_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "loss4 = twopfive_m_ten_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "loss5 = five_m_five_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "loss6 = five_m_ten_l[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n",
    "\n",
    "loss0 = pd.DataFrame(consolidated_results).T[['BNB_eod_remain', 'WETH_eod_remain', 'WBTC_eod_remain']].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([loss0, loss1, loss2, loss3, loss4, loss5, loss6],axis=1).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
